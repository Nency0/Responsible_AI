{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3518b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Abc:    \n",
    "    \n",
    "    def Accuracy_difference(X_test,y_test,model_name,model):\n",
    "        y_pred_wow=model.predict(X_test)\n",
    "        y_pred_prob_wow=model.predict_proba(X_test)[:,0]\n",
    "        print(\"Accuracy of the model {} without weights:{}\".format(model_name,model.score(X_test, y_test)))\n",
    "\n",
    "    #     for i in cols:\n",
    "    #         A_wow=model.score(X_test[X_test[i]==X_test[i].unique()[0]], y_test[X_test[i]==X_test[i].unique()[0]])\n",
    "    #         B_wow=model.score(X_test[X_test[i]==X_test[i].unique()[1]], y_test[X_test[i]==X_test[i].unique()[1]])\n",
    "    #         print(\"Accuracy difference between two groups {} :{}{} \".format(i,abs(B_wow-A_wow)*100 ,\"%\"))\n",
    "        return y_pred_wow,y_pred_prob_wow\n",
    "\n",
    "    def model_metrics(y_true, y_pred_prob_ww, y_pred_prob_wow, Y_pred_binary_ww, Y_pred_binary_wow, X_test):\n",
    "        \"\"\"\n",
    "        Model accuracy metrics for models with sample weights and without sample weights\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        :param y_true: Actual binary outcome\n",
    "        :param y_pred_prob_ww: predicted probabilities with weights\n",
    "        :param y_pred_prob_wow: predicted probabilities without weights\n",
    "        :param Y_pred_binary_ww: predicted binary outcome with weights\n",
    "        :param Y_pred_binary_wow: predicted binary outcome without weights\n",
    "        :param X_test: Xtest data [not being used here]\n",
    "        :return: roc, gini, avg precision, precision, sensitivity, tnr, fnr, f1, cost\n",
    "\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        model_perf=[model_metrics(y_test, y_pred_prob_ww, y_pred_prob_wow,\n",
    "                              y_pred_ww, y_pred_wow, X_test1)]\n",
    "\n",
    "        \"\"\"\n",
    "        tn_ww, fp_ww, fn_ww, tp_ww = confusion_matrix(y_true, Y_pred_binary_ww).ravel() #y_true, y_pred\n",
    "        tn_wow, fp_wow, fn_wow, tp_wow = confusion_matrix(y_true, Y_pred_binary_wow).ravel()\n",
    "\n",
    "        roc_ww = roc_auc_score(y_true, y_pred_prob_ww)\n",
    "        roc_wow = roc_auc_score(y_true, y_pred_prob_wow)\n",
    "\n",
    "        gini_ww = gini_normalized(y_true, y_pred_prob_ww)\n",
    "        gini_wow = gini_normalized(y_true, y_pred_prob_wow)\n",
    "\n",
    "\n",
    "        ps_ww = average_precision_score(y_true, Y_pred_binary_ww)\n",
    "        ps_wow = average_precision_score(y_true, Y_pred_binary_wow)\n",
    "\n",
    "\n",
    "        prec_ww = tp_ww / (tp_ww + fp_ww)\n",
    "        prec_wow = tp_wow / (tp_wow + fp_wow)\n",
    "\n",
    "\n",
    "        sensitivity_ww = tp_ww/(tp_ww+fn_ww)\n",
    "        sensitivity_wow = tp_wow/(tp_wow+fn_wow)\n",
    "\n",
    "        tnr_ww = tn_ww/(tn_ww + fp_ww)\n",
    "        tnr_wow = tn_wow/(tn_wow + fp_wow)\n",
    "\n",
    "\n",
    "        fnr_ww = fn_ww/(fn_ww+tp_ww)\n",
    "        fnr_wow = fn_wow/(fn_wow+tp_wow)\n",
    "\n",
    "        f1_ww = (2*tp_ww)/((2*tp_ww)+fp_ww+fn_ww)\n",
    "        f1_wow = (2*tp_wow)/((2*tp_wow)+fp_wow+fn_wow)\n",
    "\n",
    "\n",
    "\n",
    "        cost_ww = (fp_ww*700) + (fn_ww*300)\n",
    "        cost_wow = (fp_wow*700) + (fn_wow*300)\n",
    "\n",
    "        return roc_ww, gini_ww, ps_ww, prec_ww, sensitivity_ww, fnr_ww, f1_ww, cost_ww, roc_wow, gini_wow, ps_wow,  prec_wow, sensitivity_wow, fnr_wow, f1_wow, cost_wow\n",
    "\n",
    "\n",
    "    def fair_metrics(y_actual, y_pred_prob, y_pred_binary, X_test, protected_group_name,\n",
    "                     adv_val, disadv_val):\n",
    "        \"\"\"\n",
    "        Fairness performance metrics for a model to compare advantageous and disadvantageous groups of a protected variable\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        :param y_actual: Actual binary outcome\n",
    "        :param y_pred_prob: predicted probabilities\n",
    "        :param y_pred_binary: predicted binary outcome\n",
    "        :param X_test: Xtest data\n",
    "        :param protected_group_name: Sensitive feature\n",
    "        :param adv_val: Priviliged value of protected label\n",
    "        :param disadv_val: Unpriviliged value of protected label\n",
    "        :return: roc, avg precision, Eq of Opportunity, Equalised Odds, Precision/Predictive Parity, Demographic Parity, Avg Odds Diff,\n",
    "                Predictive Equality, Treatment Equality\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        fairness_metrics=[fair_metrics(y_test, y_pred_prob, y_pred,\n",
    "                         X_test, choice, adv_val, disadv_val)]\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        tn_adv, fp_adv, fn_adv, tp_adv = confusion_matrix(\n",
    "            y_actual[X_test[protected_group_name] == adv_val],\n",
    "            y_pred_binary[X_test[protected_group_name] == adv_val]).ravel()\n",
    "\n",
    "        tn_disadv, fp_disadv, fn_disadv, tp_disadv = confusion_matrix(\n",
    "            y_actual[X_test[protected_group_name] == disadv_val],\n",
    "            y_pred_binary[X_test[protected_group_name] == disadv_val]).ravel()\n",
    "\n",
    "        # Receiver operating characteristic\n",
    "        roc_adv = roc_auc_score(y_actual[X_test[protected_group_name] == adv_val],\n",
    "                                y_pred_prob[X_test[protected_group_name] == adv_val])\n",
    "        roc_disadv = roc_auc_score(y_actual[X_test[protected_group_name] == disadv_val],\n",
    "                                   y_pred_prob[X_test[protected_group_name] == disadv_val])\n",
    "\n",
    "        roc_diff = abs(roc_disadv - roc_adv)\n",
    "\n",
    "        # Average precision score\n",
    "        ps_adv = average_precision_score(\n",
    "            y_actual[X_test[protected_group_name] == adv_val],\n",
    "            y_pred_prob[X_test[protected_group_name] == adv_val])\n",
    "        ps_disadv = average_precision_score(\n",
    "            y_actual[X_test[protected_group_name] == disadv_val],\n",
    "            y_pred_prob[X_test[protected_group_name] == disadv_val])\n",
    "\n",
    "        ps_diff = abs(ps_disadv - ps_adv)\n",
    "\n",
    "        # Equal Opportunity - advantageous and disadvantageous groups have equal FNR\n",
    "        FNR_adv = fn_adv / (fn_adv + tp_adv)\n",
    "        FNR_disadv = fn_disadv / (fn_disadv + tp_disadv)\n",
    "        EOpp_diff = abs(FNR_disadv - FNR_adv)\n",
    "\n",
    "        # Predictive equality  - advantageous and disadvantageous groups have equal FPR\n",
    "        FPR_adv = fp_adv / (fp_adv + tn_adv)\n",
    "        FPR_disadv = fp_disadv / (fp_disadv + tn_disadv)\n",
    "        pred_eq_diff = abs(FPR_disadv - FPR_adv)\n",
    "\n",
    "        # Equalised Odds - advantageous and disadvantageous groups have equal TPR + FPR\n",
    "        TPR_adv = tp_adv / (tp_adv + fn_adv)\n",
    "        TPR_disadv = tp_disadv / (tp_disadv + fn_disadv)\n",
    "        EOdds_diff = abs((TPR_disadv + FPR_disadv) - (TPR_adv + FPR_adv))\n",
    "\n",
    "        # Predictive Parity - advantageous and disadvantageous groups have equal PPV/Precision (TP/TP+FP)\n",
    "        prec_adv = (tp_adv)/(tp_adv + fp_adv)\n",
    "\n",
    "        prec_disadv = (tp_disadv)/(tp_disadv + fp_disadv)\n",
    "\n",
    "        prec_diff = abs(prec_disadv - prec_adv)\n",
    "\n",
    "\n",
    "        # Demographic Parity - ratio of (instances with favourable prediction) / (total instances)\n",
    "        demo_parity_adv = (tp_adv + fp_adv) / (tn_adv + fp_adv + fn_adv + tp_adv)\n",
    "        demo_parity_disadv = (tp_disadv + fp_disadv) / \\\n",
    "            (tn_disadv + fp_disadv + fn_disadv + tp_disadv)\n",
    "        demo_parity_diff = abs(demo_parity_disadv - demo_parity_adv)\n",
    "\n",
    "        # Average of Difference in FPR and TPR for advantageous and disadvantageous groups\n",
    "        AOD = 0.5*((FPR_disadv - FPR_adv) + (TPR_disadv - TPR_adv))\n",
    "\n",
    "        # Treatment Equality  - advantageous and disadvantageous groups have equal ratio of FN/FP\n",
    "\n",
    "\n",
    "        return [('Equal Opps', EOpp_diff),\n",
    "                ('PredEq', pred_eq_diff), ('Equal Odds',\n",
    "                                           EOdds_diff), \n",
    "                ('DemoParity', demo_parity_diff), ('AOD', abs(AOD))]\n",
    "\n",
    "\n",
    "    def acf_fair_metrics(tn_disadv, fp_disadv, fn_disadv, tp_disadv, tn_adv, fp_adv, fn_adv, tp_adv):\n",
    "        \"\"\"\n",
    "        Fairness performance metrics for a additive counterfactually fair model to compare advantageous and\n",
    "        disadvantageous groups of a protected variable\n",
    "\n",
    "        :param tn_disadv: disadvantaged group's true negative\n",
    "        :param fp_disadv: disadvantaged group's false positive\n",
    "        :param fn_disadv: disadvantaged group's false negative\n",
    "        :param tp_disadv: disadvantaged group's true positive\n",
    "        :param tn_adv: advantaged group's true negative\n",
    "        :param fp_adv: advantaged group's false positive\n",
    "        :param fn_adv: advantaged group's false negative\n",
    "        :param tp_adv: advantaged group's true positive\n",
    "        :return: Equal Opportunity, Predictive Equality, Equalised Odds, Precision/Predictive Parity, Demographic Parity,\n",
    "            Avg Odds Diff, Treatment Equality\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        acf_metrics=acf_fair_metrics(tn_disadv, fp_disadv, fn_disadv, tp_disadv, tn_adv, fp_adv, fn_adv, tp_adv)\n",
    "        \"\"\"\n",
    "\n",
    "        # Equal Opportunity - advantageous and disadvantageous groups have equal FNR\n",
    "        FNR_adv = fn_adv / (fn_adv + tp_adv)\n",
    "        FNR_disadv = fn_disadv / (fn_disadv + tp_disadv)\n",
    "        EOpp_diff = abs(FNR_disadv - FNR_adv)\n",
    "\n",
    "        # Predictive equality  - advantageous and disadvantageous groups have equal FPR\n",
    "        FPR_adv = fp_adv / (fp_adv + tn_adv)\n",
    "        FPR_disadv = fp_disadv / (fp_disadv + tn_disadv)\n",
    "        pred_eq_diff = abs(FPR_disadv - FPR_adv)\n",
    "\n",
    "        # Equalised Odds - advantageous and disadvantageous groups have equal TPR + FPR\n",
    "        TPR_adv = tp_adv / (tp_adv + fn_adv)\n",
    "        TPR_disadv = tp_disadv / (tp_disadv + fn_disadv)\n",
    "        EOdds_diff = abs((TPR_disadv + FPR_disadv) - (TPR_adv + FPR_adv))\n",
    "\n",
    "        # Predictive Parity - advantageous and disadvantageous groups have equal PPV/Precision (TP/TP+FP)\n",
    "        prec_adv = (tp_adv)/(tp_adv + fp_adv)\n",
    "        prec_disadv = (tp_disadv)/(tp_disadv + fp_disadv)\n",
    "        prec_diff = abs(prec_disadv - prec_adv)\n",
    "\n",
    "        # Demographic Parity - ratio of (instances with favourable prediction) / (total instances)\n",
    "        demo_parity_adv = (tp_adv + fp_adv) / (tn_adv + fp_adv + fn_adv + tp_adv)\n",
    "        demo_parity_disadv = (tp_disadv + fp_disadv) / \\\n",
    "            (tn_disadv + fp_disadv + fn_disadv + tp_disadv)\n",
    "        demo_parity_diff = abs(demo_parity_disadv - demo_parity_adv)\n",
    "\n",
    "        # Average of Difference in FPR and TPR for advantageous and disadvantageous groups\n",
    "        AOD = 0.5*((FPR_disadv - FPR_adv) + (TPR_disadv - TPR_adv))\n",
    "\n",
    "        # Treatment Equality  - advantageous and disadvantageous groups have equal ratio of FN/FP\n",
    "        TE_adv = fn_adv/fp_adv\n",
    "        TE_disadv = fn_disadv/fp_disadv\n",
    "        TE_diff = abs(TE_disadv - TE_adv)\n",
    "\n",
    "        return [('Equal Opps', EOpp_diff),\n",
    "                ('PredEq', pred_eq_diff), ('Equal Odds',\n",
    "                                           EOdds_diff), \n",
    "                ('DemoParity', demo_parity_diff), ('AOD', abs(AOD))]\n",
    "\n",
    "\n",
    "\n",
    "    def circle(result):\n",
    "            r = 1\n",
    "            d = 10 * r * (1 - result)\n",
    "            circle1=plt.Circle((0, 0), r, alpha=.2)\n",
    "            circle2=plt.Circle((d, 0), r, alpha=.2)\n",
    "            plt.ylim([-1.1, 1.1])\n",
    "            plt.xlim([-1.1, 1.1 + d])\n",
    "            fig = plt.gcf()\n",
    "            fig.gca().add_artist(circle1)\n",
    "            fig.gca().add_artist(circle2)\n",
    "\n",
    "    def circle(result):\n",
    "            r = 1\n",
    "            d = 10 * r * (1 - result)\n",
    "            circle1=plt.Circle((0, 0), r, alpha=.2)\n",
    "            circle2=plt.Circle((d, 0), r, alpha=.2)\n",
    "            plt.ylim([-1.1, 1.1])\n",
    "            plt.xlim([-1.1, 1.1 + d])\n",
    "            fig = plt.gcf()\n",
    "            fig.gca().add_artist(circle1)\n",
    "            fig.gca().add_artist(circle2)\n",
    "\n",
    "    def oneHotEnc(df,col_name):\n",
    "        one_hot = pd.get_dummies(df[col_name], prefix=col_name)\n",
    "        df = df.drop(col_name, axis=1)\n",
    "        df = df.join(one_hot)\n",
    "        return df\n",
    "\n",
    "    def heatmap_protected(df,i):\n",
    "\n",
    "        pivot=df.reset_index().pivot_table(index=i, columns='default payment next month', aggfunc='count')\n",
    "    #     print(pivot)\n",
    "        ax = sns.heatmap(pivot, annot=True,fmt='g')\n",
    "        plt.show()\n",
    "        return pivot\n",
    "\n",
    "    def statistical_parity_test(df,protected_group,Sa_label,Sd_label,y,fav_label):\n",
    "        Sa=df[raw_data[protected_group] == Sa_label]\n",
    "        fav_Sa=Sa[Sa[y] == fav_label]\n",
    "        fav_Sa_count = len(fav_Sa)\n",
    "        Sd=df[raw_data[protected_group] == Sd_label]\n",
    "        fav_Sd=Sd[Sd[y] == fav_label]\n",
    "        fav_Sd_count = len(fav_Sd)\n",
    "        adv=len(Sa)\n",
    "        disadv=len(Sd)\n",
    "        statistical_parity.append((fav_Sd_count/disadv)-(fav_Sa_count/adv))\n",
    "        disparate_impact.append((fav_Sd_count/disadv)/(fav_Sa_count/adv))\n",
    "\n",
    "\n",
    "    def plot_SPD_DI(cols,statistical_parity,disparate_impact):\n",
    "        d = pd.DataFrame({'Protected_feature':cols,'Statistical_Parity':statistical_parity,'Disparate_Impact':disparate_impact})\n",
    "        d['DI_normal']=d[\"Disparate_Impact\"].apply(lambda x: 1/x if x < 1 else x)\n",
    "        d['SP_normal']=d[\"Statistical_Parity\"].apply(lambda x: abs(x) if x < 0 else x)\n",
    "\n",
    "        fig = plt.figure() \n",
    "        ax = fig.add_subplot(111) \n",
    "        ax2 = ax.twinx() # Create another axes that shares the same x-axis as ax.\n",
    "\n",
    "        fig.suptitle('Normalised Statistical Parity Difference and Disparate Impact for comparison', fontsize=40, y=1)\n",
    "\n",
    "        width = 0.3\n",
    "        ax.set_ylim(0, 0.25) \n",
    "        ax2.set_ylim(0, 1.5) \n",
    "\n",
    "        d.plot(x ='Protected_feature', y='SP_normal', kind = 'bar', ax=ax, width=width, \n",
    "               position=1, color='green', legend=False, figsize=(30,10), fontsize=20)\n",
    "        d.plot(x ='Protected_feature', y='DI_normal', kind = 'bar', ax=ax2, width=width, \n",
    "               position=0, color='black', legend=False, figsize=(30,10), fontsize=20)\n",
    "\n",
    "        ax.axhline(y=0.10, linestyle='dashed', linewidth=2, alpha=0.7, color='green')\n",
    "        ax2.axhline(y=0.80, linestyle='dashed', linewidth=2, alpha=0.7, color='black')\n",
    "\n",
    "        patches, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(patches, ['Stat Parity Diff'], loc='upper left', fontsize=25)\n",
    "\n",
    "        patches, labels = ax2.get_legend_handles_labels()\n",
    "        ax2.legend(patches, ['Disparate Impact'], loc='upper right', fontsize=25)\n",
    "\n",
    "        labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.set_xlabel('Protected Groups', fontsize=25)\n",
    "        ax.set_ylabel('Statistical Parity Difference', fontsize=25)\n",
    "        ax2.set_ylabel('Disparate Impact', fontsize=25)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def Reweighing1 (data, choice, target_feature, pval, upval, fav=0, unfav=1):\n",
    "\n",
    "\n",
    "        dummy = np.repeat(1, len(data)) \n",
    "        data['dummy'] = dummy\n",
    "\n",
    "        n = np.sum(data['dummy']) #Total number of instances\n",
    "        sa = np.sum(data['dummy'][data[choice]==pval]) #Total number of privileged\n",
    "        sd = np.sum(data['dummy'][data[choice]==upval]) #Total number of unprivileged\n",
    "        ypos = np.sum(data['dummy'][data[target_feature]==fav]) #Total number of favourable\n",
    "        yneg = np.sum(data['dummy'][data[target_feature]==unfav]) #Total number of unfavourable\n",
    "\n",
    "        data_sa_ypos = data[(data[choice]==pval) & (data[target_feature]==fav)] # priviliged and favourable\n",
    "        data_sa_yneg = data[(data[choice]==pval) & (data[target_feature]==unfav)] # priviliged and unfavourable\n",
    "        data_sd_ypos = data[(data[choice]==upval) & (data[target_feature]==fav)] # unpriviliged and favourable\n",
    "        data_sd_yneg = data[(data[choice]==upval) & (data[target_feature]==unfav)] # unpriviliged and unfavourable\n",
    "\n",
    "        sa_ypos = np.sum(data_sa_ypos['dummy']) #Total number of privileged and favourable\n",
    "        sa_yneg = np.sum(data_sa_yneg['dummy']) #Total number of privileged and unfavourable\n",
    "        sd_ypos = np.sum(data_sd_ypos['dummy']) #Total number of unprivileged and favourable\n",
    "        sd_yneg = np.sum(data_sd_yneg['dummy']) #Total number of unprivileged and unfavourable\n",
    "\n",
    "        w_sa_ypos= (ypos*sa) / (n*sa_ypos) #weight for privileged and favourable\n",
    "        w_sa_yneg = (yneg*sa) / (n*sa_yneg) #weight for privileged and unfavourable\n",
    "        w_sd_ypos = (ypos*sd) / (n*sd_ypos) #weight for unprivileged and favourable\n",
    "        w_sd_yneg = (yneg*sd) / (n*sd_yneg) #weight for unprivileged and unfavourable\n",
    "\n",
    "        datatest=data #.copy()\n",
    "\n",
    "    #     print (w_sa_ypos, w_sa_yneg, w_sd_ypos, w_sd_yneg)\n",
    "\n",
    "        DiscriminationBefore=(sa_ypos/sa)-(sd_ypos/sd)\n",
    "        DiscriminationAfter=(sa_ypos/sa * w_sa_ypos)-(sd_ypos/sd * w_sd_ypos)\n",
    "\n",
    "\n",
    "        print (\"DiscriminationBefore: {} \\nDiscriminationAfter: {}  \".format(DiscriminationBefore, DiscriminationAfter))\n",
    "\n",
    "        datatest['NewWeights']= np.repeat(999, len(datatest)) \n",
    "        datatest.loc[(datatest[choice]==pval) & (datatest[target_feature]==fav), 'NewWeights'] = w_sa_ypos\n",
    "        datatest.loc[(datatest[choice]==pval) & (datatest[target_feature]==unfav), 'NewWeights'] = w_sa_yneg\n",
    "        datatest.loc[(datatest[choice]==upval) & (datatest[target_feature]==fav), 'NewWeights'] = w_sd_ypos\n",
    "        datatest.loc[(datatest[choice]==upval) & (datatest[target_feature]==unfav), 'NewWeights'] = w_sd_yneg\n",
    "\n",
    "        return datatest['NewWeights']\n",
    "\n",
    "    def split_data(df):\n",
    "        x=df.drop(\"default payment next month\", axis=1)\n",
    "\n",
    "        y=df[['default payment next month']]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=6666)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "    def gini(actual, pred):\n",
    "        \"\"\"\n",
    "\n",
    "        :param actual: actual values\n",
    "        :param pred: predicted probablities\n",
    "        :return: gini scores\n",
    "        \"\"\"\n",
    "        assert (len(actual) == len(pred))\n",
    "        all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "        all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
    "        totalLosses = all[:, 0].sum()\n",
    "        giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
    "\n",
    "        giniSum -= (len(actual) + 1) / 2.\n",
    "        return giniSum / len(actual)\n",
    "\n",
    "    def gini_normalized(actual, pred):\n",
    "        \"\"\"\n",
    "\n",
    "        :param actual: actual values\n",
    "        :param pred: predicted probablities\n",
    "        :return: normalized gini scores\n",
    "        \"\"\"\n",
    "        return gini(actual, pred) / gini(actual, actual)\n",
    "\n",
    "    def model_perff(y_test, y_pred_prob_ww, y_pred_prob_wow, y_pred_ww, y_pred_wow, X_test1):\n",
    "\n",
    "        model_perf=[model_metrics(y_test, y_pred_prob_ww, y_pred_prob_wow, \n",
    "                                  y_pred_ww, y_pred_wow, X_test1)]\n",
    "\n",
    "        headers=[\"AUC\", \"Gini\", \"Avg Precision Score\", \"Precision\", \"Sensitivity\", \"False Negative Rate\", \n",
    "                 \"F1 Score\", \"Total Cost\"]\n",
    "\n",
    "\n",
    "        #full_metric={'With Weights':B, \n",
    "        #             'Without_Weights':list(ww[0]), 'Without_Weights':list(wow[0])}\n",
    "\n",
    "        #compare_table=pd.DataFrame.from_dict(ww_wow)\n",
    "\n",
    "        B = list(model_perf[0])[:len(list(model_perf[0]))//2]\n",
    "        C = list(model_perf[0])[len(list(model_perf[0]))//2:]\n",
    "\n",
    "\n",
    "        model_table={'Metrics':headers, \n",
    "                     'With_Weights':B, 'Without_Weights':C}\n",
    "\n",
    "        model_table_df=pd.DataFrame.from_dict(model_table)\n",
    "        model_table_df.loc[8] = ['Total Cost (in Mn)', model_table_df.iloc[7,1]/10000000, model_table_df.iloc[7,2]/10000000]\n",
    "        return model_table_df\n",
    "\n",
    "    def data_acf(df)  :\n",
    "        dataacf = df[['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'PAY_0', 'PAY_2', 'PAY_3',\n",
    "           'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
    "           'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',\n",
    "           'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
    "           'default payment next month', 'MARRIAGE_0', 'MARRIAGE_1', 'MARRIAGE_2',\n",
    "           'MARRIAGE_3', 'age_bins_(21, 41]', 'age_bins_(41, 61]',\n",
    "           'age_bins_(61, 81]']]\n",
    "        return dataacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e363a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
